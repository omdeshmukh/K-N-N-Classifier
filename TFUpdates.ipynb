{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFUpdates.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omdeshmukh/K-N-N-Classifier/blob/master/TFUpdates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG3PRCdXWFLW",
        "colab_type": "code",
        "outputId": "5c218eb3-e8b2-46c5-c22e-c07b6c339566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.1.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.17.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (41.6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.1.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_IkMGuTU5WB",
        "colab_type": "text"
      },
      "source": [
        "**1. Eager execution by default**\n",
        "In TensorFlow 2.0, you no longer need to create a session and run the computational graph within that. Eager execution is enabled by default in the 2.0 release so that you can build your models and run them instantly. You can choose to disable the eager execution like so:\n",
        "\n",
        "tf.compat.v1.disable_eager_execution() (provided tensorflow is imported with tf alias.)\n",
        "\n",
        "Here's a little code-based comparison that shows this difference -\n",
        "\n",
        "![alt text](https://cdn1.imggmi.com/uploads/2019/11/30/e704a3cd0c2e4b26b957136cf8a00b2f-full.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFp_h1tDVV9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing tensorflow \n",
        "import tensorflow as tf \n",
        "  \n",
        "# creating nodes in computation graph \n",
        "node1 = tf.constant(3, dtype=tf.int32) \n",
        "node2 = tf.constant(5, dtype=tf.int32) \n",
        "node3 = tf.add(node1, node2) \n",
        "  \n",
        "# create tensorflow session object \n",
        "sess = tf.Session() \n",
        "  \n",
        "# evaluating node3 and printing the result \n",
        "print(\"Sum of node1 and node2 is:\",sess.run(node3)) \n",
        "  \n",
        "# closing the session \n",
        "sess.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyYUqzxWV5T9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##2. tf.function and AutoGraph \n",
        "\n",
        "While eager execution enables you with imperative programming, when it comes to distributed training, full-scale optimization, production environments TensorFlow 1.x style graph execution has its advantages over eager execution. In TensorFlow 2.0, you retain graph based executions but in a more flexible way. It is achieved with [tf.function](https://www.tensorflow.org/alpha/tutorials/eager/tf_function) and [AutoGraph](https://www.tensorflow.org/alpha/guide/autograph).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o7qUP5YW_E7",
        "colab_type": "text"
      },
      "source": [
        "tf.function allows you to define TensorFlow graphs with Python-style syntax via its AutoGraph feature. AutoGraph supports a good range of Python compatibility including if-statement, for-loop, while-loop, Iterators, etc. However, there are limitations. Here you can find the complete list of supports that are currently available. Below is an example that shows you how easy it is to define a TensorFlow graph with just a decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1TGzUdxU1US",
        "colab_type": "code",
        "outputId": "70bff3f7-0a96-477e-e3f1-119767b7c7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the forward pass\n",
        "@tf.function\n",
        "def single_layer(x, y):\n",
        "    return tf.nn.relu(tf.matmul(x, y))\n",
        "\n",
        "# Generate random data drawn from a uniform distribution\n",
        "x = tf.random.uniform((2, 3))\n",
        "y = tf.random.uniform((3, 5))\n",
        "\n",
        "single_layer(x, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=25, shape=(2, 5), dtype=float32, numpy=\n",
              "array([[1.8779991 , 1.6349884 , 1.6660774 , 0.81102556, 1.5543084 ],\n",
              "       [0.5507065 , 0.327556  , 0.40226293, 0.3816734 , 0.23649904]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXOJU9u9ZaUy",
        "colab_type": "text"
      },
      "source": [
        "**3. tf.variable_scope no longer needed**\n",
        "\n",
        "In TensorFlow 1.x, to be able to use tf.layers as variables and to reuse them, you had to use the tf.variable block. But this is no longer needed in TensorFlow 2.0. Because of the presence of keras as the center high-level API in TensorFlow 2.0, all the layers created using tf.layers can easily be put into a tf.keras.Sequential definition. This makes the code much easier to read, and you get to keep track of the variables and losses as well.\n",
        "\n",
        "Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKC8dsNDVlQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "  \n",
        "# creating nodes in computation graph \n",
        "node = tf.Variable(tf.zeros([2,2])) \n",
        "  \n",
        "# running computation graph \n",
        "with tf.Session() as sess: \n",
        "  \n",
        "    # initialize all global variables  \n",
        "    sess.run(tf.global_variables_initializer()) \n",
        "  \n",
        "    # evaluating node \n",
        "    print(\"Tensor value before addition:\\n\",sess.run(node)) \n",
        "  \n",
        "    # elementwise addition to tensor \n",
        "    node = node.assign(node + tf.ones([2,2])) \n",
        "  \n",
        "    # evaluate node again \n",
        "    print(\"Tensor value after addition:\\n\", sess.run(node)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToeIo90HYqyK",
        "colab_type": "code",
        "outputId": "873d73f4-94c2-47bb-c42e-5d55df1b66d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "# Get the output probabilities\n",
        "out_probs = model(X_train.astype(np.float32), training=True)\n",
        "print(out_probs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.02391199 0.07779638 0.23267893 ... 0.12131068 0.04016845 0.08540832]\n",
            " [0.04233986 0.08094802 0.07623617 ... 0.16874245 0.08631705 0.1727698 ]\n",
            " [0.04618107 0.08405012 0.07311886 ... 0.10072763 0.0787909  0.20339897]\n",
            " ...\n",
            " [0.0335169  0.10829289 0.11154137 ... 0.15243632 0.07921388 0.06846298]\n",
            " [0.08170812 0.05667927 0.10128909 ... 0.08080354 0.09516545 0.18862212]\n",
            " [0.08649439 0.09137674 0.15487011 ... 0.10834958 0.04255345 0.13164042]], shape=(60000, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8Zftcua9PX",
        "colab_type": "text"
      },
      "source": [
        "In the above example, you passed the training data through the model just to get the raw output probabilities. Notice that it is just a forward pass. You can, of course, go ahead and train your model -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9agMf0eObAl-",
        "colab_type": "code",
        "outputId": "91a4b1fc-f9d0-49c6-e1b9-7a5a9249e1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2936 - accuracy: 0.9146\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1432 - accuracy: 0.9570\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1063 - accuracy: 0.9676\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0873 - accuracy: 0.9728\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0736 - accuracy: 0.9763\n",
            "10000/10000 [==============================] - 0s 44us/sample - loss: 2.4188 - accuracy: 0.0892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.4187905712127686, 0.0892]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX6njjnpdGTZ",
        "colab_type": "text"
      },
      "source": [
        "**4. Custom layers made very easy**\n",
        "\n",
        "In machine learning research or even in industrial applications, there is often a need for writing custom layers to cater to specific use cases. TensorFlow 2.0 makes it super easy to write a custom layer and use it along with the existing layers. You can also customize the forward pass of your model in any way you want.\n",
        "\n",
        "In order to create a custom layer, the easiest option is to extend the Layer class from tf.keras.layers and then define it accordingly. You will create a custom layer, and then define its forward computations. The following is the output of executing help(tf.keras.layers.Layer). It tells you what things you need to specify in order to get this done:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ6zrufCsjo_",
        "colab_type": "text"
      },
      "source": [
        "Taking advice from the above snippet, you will -\n",
        "\n",
        "Define the constructor with the number of the outputs  \n",
        "In the build() method you will add the weights for your layer  \n",
        "Finally in the call() method you will define the forward pass by chaining matrix multiplication and relu() together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ6rFtB2dK16",
        "colab_type": "code",
        "outputId": "46c5dcf2-2d5e-4493-d934-c30a50d0537d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "    # Define the constructor\n",
        "    def __init__(self, num_outputs):\n",
        "        super(MyDenseLayer, self).__init__()\n",
        "        self.num_outputs = num_outputs\n",
        "    # Define the build function to add the weights\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_variable(\"kernel\",\n",
        "                                    shape=[input_shape[-1],\n",
        "                                           self.num_outputs])\n",
        "    # Define the forward pass\n",
        "    def call(self, input):\n",
        "        matmul = tf.matmul(input, self.kernel)\n",
        "        return tf.nn.relu(matmul)\n",
        "\n",
        "# Initialize the layer with 10 output units\n",
        "layer = MyDenseLayer(10)\n",
        "# Supply the input shape\n",
        "layer(tf.random.uniform((10,3)))\n",
        "# Display the trainable parameters of the layer\n",
        "print(layer.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'my_dense_layer/kernel:0' shape=(3, 10) dtype=float32, numpy=\n",
            "array([[-0.05118656, -0.42643565, -0.19877958,  0.62027943,  0.1399877 ,\n",
            "        -0.44563115, -0.12105483, -0.6775005 , -0.16311705, -0.3422844 ],\n",
            "       [ 0.13067198,  0.08642423,  0.37010002, -0.14384723, -0.22414318,\n",
            "        -0.6297847 , -0.37664208,  0.06956828,  0.14116639, -0.0602535 ],\n",
            "       [-0.22287962, -0.4287195 ,  0.5242195 , -0.13652539, -0.27083334,\n",
            "        -0.66345704,  0.39776742, -0.03789777, -0.4244084 ,  0.06998891]],\n",
            "      dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRjIjggls4Kt",
        "colab_type": "text"
      },
      "source": [
        "You can compose multiple layers by extending Model class from tf.keras. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKwobwlFtrgZ",
        "colab_type": "text"
      },
      "source": [
        "**5. Flexibility in model training**\n",
        "\n",
        "TensorFlow can use automatic differentiation to compute the gradients of the loss function with respect to model parameters. tf.GradientTape creates a tape within a context which is used by TensorFlow to keep track of the gradients recorded from each computation in that tape. To understand this, let's define a model in a more low-level way by extending the tf.keras.Model class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1kGzWMdt10O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.do1 = tf.keras.layers.Dropout(rate=0.2, input_shape=(14,))\n",
        "        self.fc1 = tf.keras.layers.Dense(units=64, activation='relu')\n",
        "        self.do2 = tf.keras.layers.Dropout(rate=0.2)\n",
        "        self.fc2 = tf.keras.layers.Dense(units=64, activation='relu')\n",
        "        self.do3 = tf.keras.layers.Dropout(rate=0.2)\n",
        "        self.out = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.do1(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.do2(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.do3(x)\n",
        "        return self.out(x)\n",
        "\n",
        "model = CustomModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCcSvPKyuA9V",
        "colab_type": "text"
      },
      "source": [
        "Notice that the topology of this model is exactly the same as the one you defined earlier. To be able to train this model using automatic differentiation, you need to define the loss function and the optimizer differently -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJjiw4qpt80j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKWNNh2MuKVQ",
        "colab_type": "text"
      },
      "source": [
        "You will now define the metrics which will be used to measure the performance of the network during its training. By performance, model's loss and accuracy are meant here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGC8_SAKuPX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average the loss across the batch size within an epoch\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_acc = tf.keras.metrics.BinaryAccuracy(name='train_acc')\n",
        "\n",
        "valid_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "valid_acc = tf.keras.metrics.BinaryAccuracy(name='valid_acc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmrPDKq0uVhn",
        "colab_type": "text"
      },
      "source": [
        "tf.data provides utility methods to define input data pipelines. This is particularly very useful when you are dealing with a large volume of data.\n",
        "\n",
        "You will now define the data generator, which will generate batches of data during the model's training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDeVd2z0umW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = X_train.astype(np.float32), X_test.astype(np.float32)\n",
        "y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n",
        "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n",
        "\n",
        "# Batches of 64\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4KM7XyCuqyE",
        "colab_type": "text"
      },
      "source": [
        "You are now ready to train the model using tf.GradientTape. Firstly, you will define a method which will train the model with the data you just defined using tf.data.DataSet. You will also wrap the model training steps with the tf.function decorator to take advantage of the speedup it offers in the computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U19bvCr4udGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "@tf.function\n",
        "def model_train(features, labels):\n",
        "    # Define the GradientTape context\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Get the probabilities\n",
        "        predictions = model(features)\n",
        "        # Calculate the loss\n",
        "        loss = loss_func(labels, predictions)\n",
        "    # Get the gradients\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    # Update the weights\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_acc(labels, predictions)\n",
        "# Validating the model\n",
        "@tf.function\n",
        "def model_validate(features, labels):\n",
        "    predictions = model(features)\n",
        "    t_loss = loss_func(labels, predictions)\n",
        "\n",
        "    valid_loss(t_loss)\n",
        "    valid_acc(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yxU2YTt9YaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(5):\n",
        "    for features, labels in train_ds:\n",
        "        model_train(features, labels)\n",
        "\n",
        "    for test_features, test_labels in test_ds:\n",
        "        model_validate(test_features, test_labels)\n",
        "\n",
        "    template = 'Epoch {}, train_loss: {}, train_acc: {}, train_loss: {}, test_acc: {}'\n",
        "    print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_acc.result()*100,\n",
        "                         valid_loss.result(),\n",
        "                         valid_acc.result()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Yur1s1vSwT",
        "colab_type": "text"
      },
      "source": [
        "**6. TensorFlow datasets**\n",
        "\n",
        "A separate module named DataSets is used to operate with the network model in an elegant way. You already saw this in the earlier example. In this section, you will see how you can load in the MNIST dataset just in the way you want.\n",
        "\n",
        "You can install the tensorflow_datasets library with pip. Once it is installed, you are ready to go. It provides several utility functions to help you flexibly prepare your dataset construction pipeline. You can learn more about these functions here and here. You will now see how you can build a data input pipeline to load in the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNv1EoHO8cPm",
        "colab_type": "code",
        "outputId": "0a5cca98-7c0c-47fa-aede-509ba9f74d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!pip install tensorflow_datasets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.28.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.17.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.1.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (19.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.8.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (41.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdwrcO5M9C-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# You can fetch the DatasetBuilder class by string\n",
        "mnist_builder = tfds.builder(\"mnist\")\n",
        "\n",
        "# Download the dataset\n",
        "mnist_builder.download_and_prepare()\n",
        "\n",
        "# Construct a tf.data.Dataset: train and test\n",
        "ds_train, ds_test = mnist_builder.as_dataset(split=[tfds.Split.TRAIN, tfds.Split.TEST])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g7mW0XnvZtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare batches of 128 from the training set\n",
        "ds_train = ds_train.batch(128)\n",
        "\n",
        "# Load in the dataset in the simplest way possible\n",
        "for features in ds_train:\n",
        "    image, label = features[\"image\"], features[\"label\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_3SHv_WviEI",
        "colab_type": "text"
      },
      "source": [
        "You can now display the first image from the collection of images you loaded in. Note that tensorflow_datasets works in eager mode and in a graph based setting as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D5oay3Yvd93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# You can convert a TensorFlow tensor just by using\n",
        "# .numpy()\n",
        "plt.imshow(image[0].numpy().reshape(28, 28), cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8u-QI90vqXv",
        "colab_type": "text"
      },
      "source": [
        "**7. Automatic mixed precision policy**\n",
        "\n",
        "The mixed precision policy was proposed by NVIDIA last year. You can find the original paper here.\n",
        "https://arxiv.org/abs/1710.03740  \n",
        "\n",
        " The brief idea behind the mixed precision policy is to use a mixture of half (FP16) and full precision (FP32) and take advantages of both the worlds. It has shown amazing results in the training of very deep neural networks (both in terms of time and score).\n",
        "\n",
        "If you are on a CUDA enabled GPU environment (Volta Generation, Tesla T4 for example) and you installed the GPU variant of TensorFlow 2.0, you can instruct TensorFlow to train in mixed precision like so -\n",
        "\n",
        "**os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'**\n",
        "\n",
        "This will automatically cast the operations of a TensorFlow graph accordingly. You will be able to see a good amount of boost in your model's performance. You can also optimize TensorFlow core operations with mixed precision policy. Check this article   \n",
        "https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
        "  to know more about this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfBaRl7Ivyhz",
        "colab_type": "text"
      },
      "source": [
        "**8. Distributed training**\n",
        "\n",
        "TensorFlow 2.0 makes it super easy to distribute the training process across multiple GPUs. This is particularly useful for production purpose when you have to meet super heavy loads. This is as easy as putting your model training block inside a with block.\n",
        "\n",
        "First, you specify a distribution strategy like so:\n",
        "\n",
        "**mirrored_strategy = tf.distribute.MirroredStrategy()** \n",
        "\n",
        "A mirrored strategy creates one replica per GPU and the model variables are equally mirrored across GPUs. You can now use the defined strategy like the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT_EPrZRvsrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with mirrored_strategy.scope():\n",
        "    model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\n",
        "    model.compile(loss='mse', optimizer='sgd')\n",
        "    model.fit(X_train, y_train,\n",
        "             validation_data=(X_test, y_test),\n",
        "             batch_size=128,\n",
        "             epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdJXJP_Nv5ht",
        "colab_type": "text"
      },
      "source": [
        "Note that the above piece of code will only be useful if you have multiple GPUs configured on a single system. There are a number of distribution strategies you can configure. You can find more about it \n",
        "\n",
        "https://www.tensorflow.org/guide/distributed_training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYeWVXjWwDQ_",
        "colab_type": "text"
      },
      "source": [
        "**9. TensorBoard within Jupyter Notebook**\n",
        "\n",
        "You can visualize the model training directly within your Jupyter Notebook via TensorBoard. The new TensorBoard is loaded with a lot of exciting features like memory profiling, viewing image data including confusion matrix, conceptual model graph and so on. You can find more about this here\n",
        " https://www.tensorflow.org/tensorboard/get_started\n",
        "\n",
        "In this section, you will configure your environment such that the TensorBoard is displayed within Jupyter Notebook. You will first have to load the tensorboard.notebook notebook extension -\n",
        "\n",
        "%load_ext tensorboard.notebook\n",
        "\n",
        "You will now define the TensorBoard callback using the **tf.keras.callbacks** module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOk4M7wsv8fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Make a directory to keep the training logs\n",
        "os.mkdir(\"logs\")\n",
        "\n",
        "# Set the callback\n",
        "logdir = \"logs\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "#Rebuild the model using the Sequential API of tf.keras -\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dropout(rate=0.2, input_shape=X_train.shape[1:]),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yefyf8HLwiF-",
        "colab_type": "text"
      },
      "source": [
        "The train and test sets were modified for different uses. So, it will be a good idea to split them once again -\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmpHYLnUwpV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "You are all ready to train the model -\n",
        "\n",
        "# The TensorBoard extension\n",
        "%tensorboard --logdir logs/\n",
        "# Pass the TensorBoard callback you defined\n",
        "model.fit(X_train, y_train,\n",
        "         validation_data=(X_test, y_test),\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         callbacks=[tensorboard_callback],\n",
        "         verbose=False)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMPJMmxCw20E",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The TensorBoard dashboard should be loaded in your Jupyter Notebook, and you should be able to trace the training and validation metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5YPNvLnw6ai",
        "colab_type": "text"
      },
      "source": [
        "**10. TensorFlow for Swift**\n",
        "\n",
        "Despite all the incredible success, one thing very saddening about Python is that it is slow. To help researchers, practitioners, and even beginners, the TensorFlow team has developed a version for Swift. Although it is not as production ready as the Python variant it certainly has the potential. Swift allows for more low-level interactions and advanced compilation modules.\n",
        "\n",
        "https://github.com/tensorflow/swift\n",
        "\n",
        "This is where you will be able to find everything related to TensorFlow's Swift variant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seIBzlOH4FEf",
        "colab_type": "text"
      },
      "source": [
        "Source :  https://morioh.com/p/e4113febe7ed\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/ten-important-updates-tensorflow"
      ]
    }
  ]
}